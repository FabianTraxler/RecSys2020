{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext, SQLContext, SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, IntegerType, StringType, FloatType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, Tokenizer, RegexTokenizer, StopWordsRemover, HashingTF, CountVectorizer, IDF, ChiSqSelector, Normalizer\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "    \n",
    "\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Session for Assignment 3 - Evaluation (Token IDs and Hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Spark Config\n",
    "conf = SparkConf().setAppName(\"RecSys-Challenge-Train-Model\").setMaster(\"yarn\")\n",
    "conf = (conf.set(\"deploy-mode\",\"cluster\")\n",
    "       .set(\"spark.driver.memory\",\"100g\")\n",
    "       .set(\"spark.executor.memory\",\"100g\")\n",
    "       .set(\"spark.driver.cores\",\"1\")\n",
    "       .set(\"spark.num.executors\",\"50\")\n",
    "       .set(\"spark.executor.cores\",\"5\")\n",
    "       .set(\"spark.driver.maxResultSize\", \"100g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (sql.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"false\")\n",
    "    .option(\"sep\", \"\\x01\")\n",
    "    .load(path,  inferSchema=\"true\")\n",
    "    .repartition(1000)\n",
    "    .toDF(\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"engaging_user_follower_count\", \"engaging_user_following_count\", \"engaging_user_is_verified\",\"engaging_user_account_creation\", \"engaged_follows_engaging\", \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['text_tokens', 'hashtags', 'reply_timestamp', \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+\n",
      "|         text_tokens|            hashtags|reply_timestamp|retweet_timestamp|retweet_with_comment_timestamp|like_timestamp|\n",
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+\n",
      "|101\t56898\t137\t144...|CB6D1FF72208B50EA...|           null|             null|                          null|          null|\n",
      "|101\t146\t10134\t110...|                null|           null|             null|                          null|    1581464993|\n",
      "|101\t56898\t137\t469...|                null|           null|             null|                          null|          null|\n",
      "|101\t16986\t12713\t1...|                null|           null|             null|                          null|    1581472788|\n",
      "|101\t10057\t7138\t30...|6FF21860E3E64036C...|           null|             null|                          null|          null|\n",
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Engagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_cols = ['reply_timestamp', 'retweet_timestamp', 'retweet_with_comment_timestamp', 'like_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in response_cols:\n",
    "    df = df.withColumn(\n",
    "        col,\n",
    "        F.when((F.col(col) >= 0), 1)\\\n",
    "        .otherwise(0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Token ID's with Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({'hashtags':'nohashtag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'token_and_hashtags',\n",
    "    F.concat(F.col(\"text_tokens\"), F.lit(\"\\t\"), F.col(\"hashtags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[text_tokens: string, hashtags: string, reply_timestamp: int, retweet_timestamp: int, retweet_with_comment_timestamp: int, like_timestamp: int, token_and_hashtags: string]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of all 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 1st Model \"reply_timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mPath_reply =  \"model_reply_bestModel_big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"reply_timestamp\", \"label\")\n",
    "persistedModel = PipelineModel.load(mPath_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = persistedModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR Curve: 0.3647\n"
     ]
    }
   ],
   "source": [
    "auprc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"label\", \"reply_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+--------------------+\n",
      "|         text_tokens|            hashtags|reply_timestamp|retweet_timestamp|retweet_with_comment_timestamp|like_timestamp|  token_and_hashtags|\n",
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+--------------------+\n",
      "|101\t56898\t137\t146...|750431D16B3B4E656...|              0|                0|                             0|             0|101\t56898\t137\t146...|\n",
      "|101\t56898\t137\t385...|           nohashtag|              0|                0|                             0|             0|101\t56898\t137\t385...|\n",
      "|101\t56898\t137\t100...|           nohashtag|              0|                0|                             0|             0|101\t56898\t137\t100...|\n",
      "|101\t1433\t31287\t20...|           nohashtag|              0|                0|                             0|             1|101\t1433\t31287\t20...|\n",
      "|101\t56898\t137\t128...|           nohashtag|              0|                0|                             0|             0|101\t56898\t137\t128...|\n",
      "+--------------------+--------------------+---------------+-----------------+------------------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 2nd Model \"retweet_timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mPath_retweet =  \"model_retweet_bestModel_big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"retweet_timestamp\", \"label\")\n",
    "persistedModel = PipelineModel.load(mPath_reply)\n",
    "predictions = persistedModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR Curve: 0.5163\n"
     ]
    }
   ],
   "source": [
    "auprc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"label\", \"retweet_timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 3rd Model \"retweet_with_comment_timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mPath_retweet_with_comment =  \"model_retweet_with_comment_bestModel_big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"retweet_with_comment_timestamp\", \"label\")\n",
    "persistedModel = PipelineModel.load(mPath_reply)\n",
    "predictions = persistedModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR Curve: 0.1278\n"
     ]
    }
   ],
   "source": [
    "auprc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"label\", \"retweet_with_comment_timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 4th Model \"like_timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mPath_like =  \"model_like_bestModel_big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"like_timestamp\", \"label\")\n",
    "persistedModel = PipelineModel.load(mPath_reply)\n",
    "predictions = persistedModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR Curve: 0.3985\n"
     ]
    }
   ],
   "source": [
    "auprc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"label\", \"like_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.evaluation.BinaryClassificationMetrics object at 0x7f80bd200e80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anaconda3/lib/python3.6/site-packages/pyspark/mllib/common.py\", line 142, in __del__\n",
      "    self._sc._gateway.detach(self._java_model)\n",
      "AttributeError: 'BinaryClassificationMetrics' object has no attribute '_sc'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'scoreCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-99d590a4bb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoreCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'scoreCol'"
     ]
    }
   ],
   "source": [
    "bcm = BinaryClassificationMetrics(predictions, scoreCol='probability', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm = BinaryClassificationMetrics(predictions, scoreCol='probability', labelCol='Survived')\n",
    "\n",
    "# We still can get the same metrics as the evaluator...\n",
    "print(\"Area under ROC Curve: {:.4f}\".format(bcm.areaUnderROC))\n",
    "print(\"Area under PR Curve: {:.4f}\".format(bcm.areaUnderPR))\n",
    "\n",
    "# But now we can PLOT both ROC and PR curves!\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "bcm.plot_roc_curve(ax=axs[0])\n",
    "bcm.plot_pr_curve(ax=axs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
